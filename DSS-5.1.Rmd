---
title: "Time Series Forecasting Dengan Framework Modeltime"
author: "Victor Nugraha"
date: "3/8/2022"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float:
        collapsed: true
    number_sections: true
    df_print: paged
---

<style>
body {text-align: justify}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      fig.width = 8,
                      fig.height = 4,
                      fig.align = "center")
```

# Pendahuluan

<i>Time Series Forecasting</i> merupakan salah satu model dari <i>Supervised Machine Learning</i>, yang memiliki kemampuan untuk memprediksi sebuah nilai pada masa depan berdasarkan data historis khususnya data-data yang berhubungan dengan waktu. 

Pada bahasa pemrograman R sendiri, sudah banyak sekali <i>framework</i> ataupun <i>packages</i> yang dapat kita manfaatkan untuk membuat sebuah model <i>time series forecasting</i>. Dari sekian banyak framework dan packages, pada artikel ini kita akan fokus untuk melakukan eksplorasi terhadap sebuah <i>framework</i> yang masih menjadi keluarga dari `Tidymodels` yaitu <i>framework</i> `modeltime` dan sebuah package tambahan yaitu `modeltime.resample`.

<b> Kenapa Menggunakan <i>modeltime</i>?</b>

```{r, echo=F}
knitr::include_graphics("img/framework.png")
```

Salah satu alasan utama kenapa fokus dari artikel ini membahas `modeltime` karena `modeltime` adalah sebuah <i>framework</i> yang berisikan beberapa <i>model machine learning time series</i>, dari yang cukup klasik seperti <i>ARIMA</i> dan <i>Exponential Smooting</i>, sampai dengan yang cukup baru seperti <i>Facebookâ€™s Prophet</i> dan <i>parnship</i>. 

Selain itu, `modeltime` menyediakan sebuah <i>workflow</i> yang dapat kita manfaatkan sebagai panduan. Berikut adalah urutan <i>workflow</i> yang dapat kita ikuti:

* <b>Tahapan 1 - Persiapan Data</b>: Pada tahapan pertama ini akan mencangkup proses pengumpulan data, pembersihan data dan eksplorasi terhadap data kita.
* <b>Tahapan 2 - <i>Cross Validation</i></b>: Tahapan kedua yang harus dilakukan adalah memisahkan data kita menjadi data pembelajaran dan data evaluasi, proses pemisahan data tersebut nantinya bisa dibantu oleh package `modeltime.resample` yang masih menjadi keluarga dari `modeltime`. 
* <b>Tahapan 3 - Mempersiapkan <i>Model Machine Learning</i></b>: Tahapan ketiga adalah tahapan di mana kita akan membuat <i>model machine learning time series</i>. Dikarenakan `modeltime` memiliki berbagai macam model yang dapat kita gunakan, tentu saja kita dapat membuat beberapa model sekaligus.
* <b>Tahapan 4 - Menggabungkan Model Ke Sebuah Tabel</b>: Jika kita membuat beberapa model sekaligus, kita dapat menggabungkan beberapa model tersebut ke sebuah tabel agar lebih rapi dan lebih mudah untuk dibandingkan pada tahapan berikutnya.
* <b>Tahapan 5 - Pelatihan, Evaluasi & Uji Asumsi</b>: Tahapan selanjutnya adalah melakukan prediksi terhadap data evaluasi, setelah itu kita akan melakukan evaluasai terhadap hasil prediksinya dan sekaligus melakukan uji asumsi.
* <b>Tahapan 6 - Prediksi Masa Depan</b>: Tahapan terakhir yang dapat kita lakukan adalah memprediksi masa depan.

Tentu saja sebagai seorang <i>Data Scientist</i> kita akan sangat terbantu karena kita sudah memiliki sebuah <i>framework</i> yang memungkinkan kita untuk bekerja lebih cepat dan rapi. 

# Library

```{r}
# Data Preparation
library(tidyverse)
library(lubridate)
library(timetk)

# Data Visualization
library(plotly)
library(glue)

# Machine Learning
library(tidymodels)
library(modeltime)
library(modeltime.resample)
```

# Modeltime Workflow

## Persiapan Data

Seperti yang sudah disampaikan di atas, pada tahapan pertama ini akan dimulai dengan proses pengumpulan data, pembersihan data dan eksplorasi data.

### Pengumpulan Data

Data yang akan digunakan di sini adalah data yang berasal dari [kaggle](https://www.kaggle.com/djzurawski/us-oil-and-gas-production-june-2008-to-june-2018).

```{r}
crude_oil <- read.csv("data_input/U.S._crude_oil_production.csv")
crude_oil 
```

Dari total 36 kolom yang terdapat pada dataframe di atas, kita hanya akan menggunakan 2 kolom saja yaitu kolom `Month` dan `U.S..Crude.Oil`. Kolom `Month` berisikan informasi tanggal setiap awal bulan dari Juni 2008 sampai Juni 2018 dan pada kolom `U.S..Crude.Oil` berisikan informasi jumlah hasil tambang minyak bumi dari setiap daerah di Amerika Serikat dalam satuan 1000 barel, jumlah hasil tambang minyak bumi pada kolom `U.S..Crude.Oil` berdasarkan penjumlahan dari 34 kolom lainnya. 

Dari kedua kolom tersebut nantinya akan coba kita manfaatkan untuk memprediksi berapa banyak minyak bumi yang dapat ditambang oleh Amerika Serikat selama satu tahun kedepan. Informasi hasil prediksi tersebut akan bermanfaat untuk negara karena minyak bumi merupakan salah satu bahan mentah yang digunakan untuk berbagai macam kebutuhan di berbagai sektor industri. Maka dari itu, hasil prediksi akan menjadi bahan pertimbangan Amerika Serikat dalam menentukan langkah kedepannya. 

Sebagai contoh, misalkan hasil prediksi menyatakan adanya penurunan hasil minyak bumi selama 1 tahun kedepan dan prediksi penurunannya sampai di titik di mana hasil tambang minyak bumi tidak dapat memenuhi kebutuhan selama 1 tahun kedepan, maka negara Amerika Serikat bisa mengambil keputusan lebih cepat untuk mengimpor minyak bumi dari negara lain agar tidak mengalami kekurangan.

### Pembersihan Data

Tahapan selanjutnya yang perlu kita lakukan adalah mempersiapkan data kita agar dapat diproses lebih lanjut. Proses pembersihan yang akan dilakukan terlebih dahulu adalah menghilangkan kolom yang tidak diperlukan, mengubah tipe data menjadi format yang lebih sesuai dan memastikan bahwa tanggalnya sudah berurutan.

```{r}
crude_oil_clean <- crude_oil %>% 
  select(Month, U.S..Crude.Oil) %>% 
  mutate(Month = ymd(Month)) %>% 
  arrange(Month)

glimpse(crude_oil_clean)
```

Selain melakukan dua proses di atas, kita juga harus memastikan bahwa tidak ada <i>missing value</i> karena jika adanya <i>missing value</i> akan sangat mempengaruhi hasil prediksi.

```{r}
crude_oil_clean %>% 
  is.na() %>% 
  colSums()
```

Dari hasil observasi di atas, kita mengetahi bahwa pada data kita tidak ada <i>missing value</i>. 

### Eksplorasi Data

Untuk mempermudah tahapan eksplorasi data untuk kasus deret waktu, kita akan membuat sebuah visualisasi garis dengan menggunakan fungsi `plot_time_series` dari `library(timetk)`. 

Hasil dari visualisasi tersebut nantinya akan sangat membantu kita untuk mengetahui apakah hasil tambang minyak bumi di Amerika Serikat memiliki sebuah pola arah atau pola musiman. Jika nantinya dari hasil visualisasi menunjukan bahwa data deret waktu tidak memiliki pola arah dan tidak pola musiman, maka dapat dikategorikan sebagai data stasioner. Jika memiliki salah satu di antara pola arah atau pola musiman, maka dapat dikategorikan sebagai data tidak stasioner.

Identifikasi mengenai kategori data pada kasus deret waktu merupakan hal yang penting karena akan menentukan pendekatan yang akan digunakan nantinya. 

```{r, fig.width=8}
crude_oil_clean %>%
  plot_time_series(.date_var = Month, 
                   .value = U.S..Crude.Oil, 
                   .line_size = 1, 
                   .smooth_size = 0.5,
                   .smooth_alpha = 0.4,
                   .interactive = TRUE, 
                   .x_lab = "Tanggal", 
                   .y_lab = "Jumlah Minyak Bumi (1000 Barel)", 
                   .title = "Hasil Tambang Minyak Bumi Amerika Serikat (Juni 2008 - September 2018)")
```

Dari hasil visualisasi di atas, kita bisa menarik kesimpulan bahwa data hasil tambang minyak bumi di Amerika Serikat tidak memiliki pola musiman tapi memiliki pola arah yang cenderung meningkat dari waktu ke waktu, maka dari itu data tersebut dapat dikategorikan sebagai data tidak stasioner. 

## Cross Validation

Langkah selanjutnya kita akan melakukan <i>cross validation</i> agar kita dapat mengevaluasi stabilitas model <i>time series forecasting</i> yang dibuat. Pada tahapan <i>cross validation</i> kali ini, kita tidak hanya membagi data pembelajaran dan data validasinya berdasarkan 1 kurun waktu saja melainkan akan dibagi ke 4 kurun waktu yang berbeda. Dengan dibaginya data pembelajaran dan data validasinya ke beberapa rentan waktu yang berbeda, kita bisa lebih yakin terhadap stabilitas model yang dibuat karena model tersebut tidak divalidasi sekali saja melainkan beberapa kali dengan kurun waktu yang berbeda-beda.

Untuk membagi data kita ke 4 kurun waktu yang berbeda, kita akan dibantu dengan sebuah fungsi `time_series_cv()` dari `library(modeltime.resample)`. Pada fungsi tersebut nantinya akan ada 5 parameter yang bisa diisi, yaitu:

- `data`: Data frame yang ingin digunakan.
- `assess`: Rentan waktu untuk data validasi.
- `initial`: Rentan waktu untuk data pembelajaran.
- `skip`: Jarak waktu antara setiap pembagian data pembelajaran dan data validasi.
- `slice_limit`: Berapa banyak pembagian data akan dilakukan.

```{r}
resamples_tscv <- time_series_cv(
    data        = crude_oil_clean,
    assess      = "1 year",
    initial     = "5 years",
    skip        = "1 year",
    slice_limit = 4
)
```

Agar mendapatkan gambaran yang lebih jelas lagi bagaimana fungsi `time_series_cv()` bekerja, kita dapat melihat bagaimana hasil pembagian data ke 4 kurun waktu yang berbeda untuk setiap data pembelajaran dan data validasinya dari visualisasi di bawah ini.

```{r}
resamples_tscv %>%
    tk_time_series_cv_plan() %>%
    plot_time_series_cv_plan(.date_var = Month, 
                             .value = U.S..Crude.Oil, 
                             .interactive = TRUE)
```

```{r, echo=F}
# plot_tscv <- 
# resamples_tscv %>%
#   tk_time_series_cv_plan() %>%
#   mutate(text = glue("Data: {.key}
#                       Tanggal: {Month}
#                       Hasil Minyak Bumi: {comma(U.S..Crude.Oil, 3)}")) %>% 
#   ggplot(mapping = aes(x = Month, 
#                        y = U.S..Crude.Oil, 
#                        group = .key,
#                        text = text)) +
#   geom_line(mapping = aes(color = .key)) +
#   facet_wrap(~.id, 
#              scales = "free_y", 
#              ncol = 4) +
#   scale_y_continuous(labels = comma) +
#   labs(title = "Time Series Cross Validation",
#        x = "",
#        y = "",
#        color = "Data") +
#   theme(axis.text.x = element_text(size = 2)) +
#   theme_light() 
# 
# ggplotly(plot_tscv, tooltip = "text", width = 1100, height = 500)
```

## Machine Learning Model

Dengan menggunakan <i>framework</i> `modeltime`, kita diberikan kebebasan untuk menggunakan berbagai macam model <i>time series forecasting</i> yang dapat disesuaikan dengan kebutuhan. Selain itu <i>framework</i> `modeltime` akan terus melakukan pengembangan <i>ecosystem</i> jadinya akan selalu ada model baru yang dapat kita manfaatkan kedepannya. 

Pada kesempatan kali ini kita akan mencoba untuk membuat tiga model terlebih dahulu, yaitu ARIMA, Exponential Smooting dan Prophet.

- <b>ARIMA</b>

Auto Regressive Integrated Moving Average atau ARIMA, merupakan sebuah model <i>time series forecasting</i> yang cukup klasik untuk digunakan untuk menghadapi data deret waktu yang tidak memiliki pola musiman. 

Akan tetapi salah satu kelemahan dari model ARIMA adalah model tersebut tidak bisa digunakan jika data yang kita gunakan belum stasioner dan berdasarkan eksplorasi data yang sudah dilakukan, data yang kita gunakan masih belum stasioner. Bentuk data yang masih stasioner dapat ditanggulangi dengan melakukan <i>differencing</i>. Dengan membuat model ARIMA berdasarkan <i>framework</i> dari `modeltime`, kita tidak perlu melakukan <i>differencing</i> secara terpisah karena pada fungsi yang akan kita gunakan akan melakukan <i>differencing</i> jika data yang digunakan masih belum stasioner.

Fungsi yang akan kita gunakan dalam membuat model ARIMA, yaitu

- `arima_reg()`: Fungsi ini digunakan untuk membuat model ARIMA dari <i>framework</i> `modeltime`.
- `set_engine()`: Fungsi ini kita gunakan untuk mengatur bagaiama model prophet tersebut akan dibuat, jika kita ingin mesin yang mencari hasil <i>hyperparameter</i> untuk model prophet kita bisa mengisinya dengan `auto_arima`.
- `fit()`: Fungsi ini kita gunakan untuk memberitahu objek data dan kolom apa yang akan digunakan sebagai prediktor dan sebagai target variabel.

```{r}
model_fit_arima <- arima_reg() %>%
    set_engine(engine = "auto_arima") %>% 
    fit(formula = U.S..Crude.Oil ~ Month, 
        data = crude_oil_clean)

model_fit_arima 
```

- <b>ETS</b>

Model kedua yang akan kita buat adalah Exponential Smoothing. Exponential Smoothing merupakan sebuah model yang cukup serbaguna karena pada model ini bisa digunakan untuk memprediksi data yang memiliki pola arah ataupun pola musiman ataupun tidak memiliki pola sama sekali. Dikarenakan kemampuan model ini yang dapat memprediksi untuk berbagai macam kasus deret waktu, model Exponential Smoothing merupakan salah satu model yang cukup populer untuk digunakan.

Sama seperti model ARIMA, pada model Exponential Smoothing yang sudah dikembangkan oleh <i>framework</i> dari `modeltime`, kita tidak perlu repot-repot dalam menentukan apakah data kita memiliki pola atau tidak karena pada fungsi yang akan kita gunakan nanti sudah terdapat sebuah fungsi yang akan membantu kita dalam menentukan hal tersebut.

Fungsi yang akan kita gunakan dalam membuat model Exponential Smoothing, yaitu

- `exp_smoothing()`: Fungsi ini digunakan untuk membuat model Exponential Smoothing dari <i>framework</i> `modeltime`.
- `set_engine()`: Fungsi ini kita gunakan untuk mengatur bagaiama model prophet tersebut akan dibuat, jika kita ingin mesin yang mencari hasil <i>hyperparameter</i> untuk model prophet kita bisa mengisinya dengan `ets`.
- `fit()`: Fungsi ini kita gunakan untuk memberitahu objek data dan kolom apa yang akan digunakan sebagai prediktor dan sebagai target variabel.

```{r}
model_fit_ets <- exp_smoothing() %>%
    set_engine(engine = "ets") %>% 
    fit(formula = U.S..Crude.Oil ~ Month, 
        data = crude_oil_clean)

model_fit_ets
```

- <b>Prophet</b>

Terakhir, model ini merupakan model <i>time series forecasting</i> yang dikembangkan oleh Facebook. Salah satu kelebihan dari model prophet adalah untuk menghadapi data deret waktu yang memiliki pola musiman yang kuat. Walaupun kelebihan dari model prophet adalah kemampuannya untuk menangkap pola musiman, bukan berarti model tersebut tidak dapat digunakan untuk data deret waktu yang memiliki pola arah.

Fungsi yang akan kita gunakan dalam membuat model prhophet, yaitu

- `prophet_reg()`: Fungsi ini digunakan untuk membuat model prhophet dari <i>framework</i> `modeltime`.
- `set_engine()`: Fungsi ini kita gunakan untuk mengatur bagaiama model prophet tersebut akan dibuat, jika kita ingin mesin yang mencari hasil <i>hyperparameter</i> untuk model prophet kita bisa mengisinya dengan `prophet`.
- `fit()`: Fungsi ini kita gunakan untuk memberitahu objek data dan kolom apa yang akan digunakan sebagai prediktor dan sebagai target variabel.

```{r}
model_fit_prophet <- prophet_reg() %>%
    set_engine(engine = "prophet") %>%
    fit(formula = U.S..Crude.Oil ~ Month, 
        data = crude_oil_clean)

model_fit_prophet
```

<i>Disclaimer</i>, ketika kita menyerahkan kepada mesin untuk mencari <i>hyperparameter</i> untuk setiap model yang kita gunakan, tidak berarti model tersebut akan menghasilkan performa yang paling baik. Jika dirasa performa yang dihasilkan nantinya kurang memuaskan, kita bisa kembali ke tahapan ini untuk mengatur <i>hyperparameter</i> secara manual.

## Penggabungan Machine Learning Model

Tahap selanjutnya yang bisa kita lakukan adalah menggabungkan ketiga model yang sudah dibuat menjadi satu kesatuan. Tujuan penggabungan dari ketiga model tersebut adalah untuk mempermudah beberapa proses selanjutnya yaitu proses pelatihan model, evaluasi model dan prediksi masa depan karena dengan menggabungkan semua model menjadi satu kesatuan, kita hanya perlu melakukan pelatihan model, evaluasi model dan prediksi sebanyak satu kali saja. 

Untuk menggabungkan beberapa model menjadi satu kesatuan, kita dapat memanfaatkan sebuah fungsi yang bernama `modeltime_table()`.

```{r}
models_tbl <- modeltime_table(model_fit_arima,
                              model_fit_prophet,
                              model_fit_ets)

models_tbl
```

## Pelatihan & Evaluasi Model

Untuk melakukan pelatihan model yang sudah dibuat dengan data yang sudah kita persiapkan pada tahapan <i>cross validation</i>, kita dapat memanfaatkan sebuah fungsi `modeltime_fit_resamples()`. Selain untuk melatih model, fungsi tersebut juga akan melakukan perhitungan error yang terjadi pada data validasi yang sudah dipersiapkan.

- <b>Pelatihan Model</b>

Nantinya fungsi `modeltime_fit_resamples()` bisa langsung melatih setiap model yang dibuat berdasarkan pembagian data yang sudah dibagi pada tahapan <i>cross validation</i> dengan menambahkan sebuah parameter yaitu `resamples`, parameter tersebut nantinya bisa kita isi dengan nama objek data hasil <i>cross validation</i>

```{r}
resamples_fitted <- models_tbl %>%
    modeltime_fit_resamples(resamples = resamples_tscv)

resamples_fitted
```

- <b>Evaluasi Model</b>

Seperti yang sempat disampaikan sebelumnya, fungsi `modeltime_fit_resamples()` juga akan melakukan perhitungan error yang dapat kita manfaatkan untuk evaluasi ketiga model yang sudah kita buat. Untuk dapat melihat hasil perhitungan error, kita akan memanfaatkan fungsi `modeltime_resample_accuracy()` dan `table_modeltime_accuracy()`. Nantinya kedua fungsi tersebut akan membuat sebuah tabel evaluasi yang berisikan 6 perhitungan evaluasi error. Akan tetapi hasil dari tabel evaluasi yang akan kita buat tidak langsung menampilkan perhitungan evaluasi error untuk setiap pembagian data, melainkan hanya untuk pembagian data yang paling akhir saja atau untuk kurun waktu dari Agustus 2009 sampai Mei 2015.

```{r, fig.width=8}
resamples_fitted %>%
    modeltime_resample_accuracy() %>%
    table_modeltime_accuracy(.title = "Tabel Evaluasi", 
                             .interactive = FALSE)
```

Opsi lain untuk melihat evaluasi model adalah dengan menggunakan fungsi `plot_modeltime_resamples()`. Fungsi tersebut nantinya akan menghasilkan 6 plot interaktif, di mana setiap plot tersebut akan mewakili sebuah perhitungan error untuk setiap pembagian data validasinya, jadinya kita dapat langsung melihat secara menyeluruh bagaimana performa model yang dibuat pada 4 data yang berbeda. 

```{r, fig.width=8}
resamples_fitted %>%
    plot_modeltime_resamples(.interactive = TRUE)
```

Dari plot evaluasi error di atas kita dapat menarik kesimpulan bahwa, model ARIMA dan Exponential Smoothing memiliki error yang relatif stabil untuk setiap 4 rentang waktu yang ada, sedangkan untuk nilai error yang dihasilkan oleh model prophet dapat disimpulkan kurang stabil. Selain itu, kita juga dapat menyimpulkan bahwa model ARIMA adalah model yang memiliki rata-rata error yang paling kecil hampir di setiap matriks evaluasi error yang digunakan. 

- <b>Uji Asumsi</b>

Selain melihat dari evaluasi nilai error yang dihasilkan, kita juga dapat melakukan uji asumsi. Uji asumsi pada kasus deret waktu dilakukan untuk mengukur apakah residual yang peroleh dari setiap model <i>time series forecasting</i> sudah cukup baik untuk menggambarkan dan menangkap informasi pada data. 

Untuk melakukan uji asumsi, kita dapat memanfaatkan 2 fungsi yang sudah disediakan oleh `modeltime`, yaitu

- `modeltime_residuals`: Fungsi ini digunakan untuk mengeluarkan nilai residual dari setiap model yang dibuat. Pada fungsi ini, kita juga harus mengisi parameter `new_data`. Parameter tersebut akan kita isi dengan data latih dari setiap rentan waktu yang sudah dipisahkan pada tahapan <i>cross validation</i>.
- `modeltime_residuals_test`: Fungsi ini digunakan untuk melakukan uji asumsi berdasarkan nilai residual dari setiap model yang dibuat. Ada 4 uji asumsi yang akan dilakukan fungsi ini, yaitu: <i>Shapiro-Wilk, Box-Pierce, Ljung-Box dan Durbin-Watson.</i>

Berikut adalah syarat dari setiap uji asumsi yang akan diujikan,

<b><i>Shapiro-Wilk</i></b>

Shapiro-Wilk menguji normalitas residual. Di mana,

- $H_0$: residual berdistribusi normal
- $H_1$: residual tidak berdistribusi normal

Yang diharapkan dari hasil uji asumsi ini adalah residual berdistribusi normal. Untuk mengetahui hal tersebut, kita akan melihat nilai p-value. Jika nilai p-value > 0,05, hal tersebut menunjukkan bahwa sebaran data tidak berbeda nyata dengan sebaran normal. Dengan kata lain, kita dapat mengasumsikan residual berdistribusi normal.

<b><i>Box-Pierce & Ljung-Box</i></b>

Ljung-Box dan Box-Pierce adalah metode yang menguji autokorelasi pada residual. Di mana,

- $H_0$: residual tidak ber-autokorelasi
- $H_1$: residual memiliki autokorelasi

Yang diharapkan dari hasil uji asumsi ini adalah residual tidak ber-autokorelasi. Untuk mengetahui hal tersebut, kita akan melihat nilai p-value. Jika nilai p-value > 0,05, hal tersebut menunjukkan bahwa residual dari data adalah independen. Dengan kata lain, kita dapat mengasumsikan residual tidak ber-autokorelasi.

<b><i>Durbin-Watson</i></b>

Durbin-Watson adalah metode lain yang menguji autokrelasi pada residual. Uji asumsi Durbin Watson melaporkan statistik uji, dengan nilai dari 0 hingga 4, di mana:

- 2 tidak ada autokorelasi 
- Dari 0 hingga <2 adalah ada  positif (umum dalam data deret waktu)
- Dari >2 hingga 4 adalah ada autokorelasi negatif (kurang umum dalam data deret waktu)

Yang diharapkan dari hasil Durbin-Watson adalah nilai 2, yang berarti residual tidak ber-autokorelasi.

```{r}
# Uji Asumsi Data Slice 1

data_train_slice1 <- resamples_tscv %>%
  tk_time_series_cv_plan() %>% 
  filter(.id == "Slice1" & .key == "testing")

models_tbl %>% 
  modeltime_residuals(new_data = data_train_slice1) %>% 
  modeltime_residuals_test()
```

```{r}
# Uji Asumsi Data Slice 2

data_train_slice2 <- resamples_tscv %>%
  tk_time_series_cv_plan() %>% 
  filter(.id == "Slice2" & .key == "testing")

models_tbl %>% 
  modeltime_calibrate(new_data = data_train_slice2) %>% 
  modeltime_residuals() %>% 
  modeltime_residuals_test()
```

```{r}
# Uji Asumsi Data Slice 3

data_train_slice3 <- resamples_tscv %>%
  tk_time_series_cv_plan() %>% 
  filter(.id == "Slice3" & .key == "testing")

models_tbl %>% 
  modeltime_calibrate(new_data = data_train_slice3) %>% 
  modeltime_residuals() %>% 
  modeltime_residuals_test()
```

```{r}
# Uji Asumsi Data Slice 4

data_train_slice4 <- resamples_tscv %>%
  tk_time_series_cv_plan() %>% 
  filter(.id == "Slice4" & .key == "testing")

models_tbl %>% 
  modeltime_calibrate(new_data = data_train_slice4) %>% 
  modeltime_residuals() %>% 
  modeltime_residuals_test()
```

Dari hasil uji asumsi yang sudah dilakukan di atas, kita dapat menarik kesimpulan bahwa model ARIMA selalu lulus uji asumsi <i>Shapiro-Wilk, Box-Pierce dan Ljung-Box</i> pada 4 rentan waktu yang berbeda dan lulus uji asumsi <i>Durbin-Watson</i> pada rentan waktu slice ke 2. Sedangkan untuk kedua model lainnya, beberapa kali gagal pada uji asumsi <i>Shapiro-Wilk, Box-Pierce dan Ljung-Box</i>.

## Prediksi Masa Depan

Pada tahapan terakhir ini, kita akan melakukan prediksi selama satu tahun kedepan untuk melihat berapa banyak minyak bumi yang dapat ditambang oleh Amerika Serikat setiap bulannya. 

Untuk melakukan prediksi, pertama-tama kita harus melatih ulang model yang sudah dilatih sebelumnya pada objek `resamples_fitted` ke keseluruhan data karena ketiga model yang kita sudah latih sebelumnya masih menggunakan data latih dengan deret waktu yang tidak utuh, sedangkan untuk mendapatkan hasil prediksi masa depan yang lebih akurat kita akan melatih ulang model kita dengan keseluruhan data deret waktu yang ada. Fungsi yang dapat kita gunakan pada proses ini adalah fungsi `modeltime_refit()`.

```{r}
refit_tbl <- resamples_fitted %>%
    modeltime_refit(data = crude_oil_clean)
```

Setelah melatih ulang model, kita akan melakukan prediksi masa depan dengan menggunakan fungsi `modeltime_forecast()` . Pada fungsi tersebut nantinya akan ada 2 parameter yang bisa diisi, yaitu:

- `h`: Seberapa jauh prediksi yang akan dilakukan.
- `actual_data`: Objek data yang ingin diprediksi.

```{r}
forecast <- refit_tbl %>%
    modeltime_forecast(h = "1 years", 
                       actual_data = crude_oil_clean) 

forecast 
```

Hasil prediksi dari fungsi `modeltime_forecast()` akan menghasilkan sebuah dataframe dan untuk melihat hasil prediksinya kita dapat melihat dari kolom `.value`. Opsi lain yang dapat kita lakukan untuk melihat hasil prediksi dari ketiga model yang kita buat adalah dengan membuat sebuah visualisasi dengan memanfaatkan fungsi `plot_modeltime_forecast()`.

```{r, fig.width=8}
forecast %>%
    plot_modeltime_forecast(.interactive = TRUE)
```

Dari visualisasi yang dihasilkan, kita dapat melihat bahwa model ARIMA dan Exponential Smoothing menghasilkan prediksi yang memiliki kenaikan konstan dari bulan ke bulannya tanpa adanya penurunan sama sekali. Prediksi yang membuat garis lurus pada model ARIMA dan Exponential Smoothing dapat terjadi dikarenakan kedua model tersebut menggunakan parameter <i>auto</i> yang menghasilkan <i>hyperparameter</i> yang tidak memperhitungkan pola musiman dan hasil tersebut cukup sering terjadi pada model <i>time sereis forecasting</i> yang menggunakan parameter <i>auto</i>.

Sedangkan untuk model prophet, model prophet menghasilkan prediksi yang tidak memiliki kenaikan konstan di setiap bulannya. Akan tetapi pada awal prediksi, model prophet langung memprediksi hasil tambang minyak bumi di Amerika Serikat pada bulan Juli 2018 sebesar 767 ribu barel.

Hasil prediksi yang dihasilkan tentu saja tidak 100% akurat, untuk mengetahui seberapa besar error yang mungkin terjadi, kita dapat memanfaatkan rata-rata nilai error pada tahapan evaluasi model sebelumnya.

<i>Disclaimer</i>: Pada tahapan prediksi model tidak harus menggunakan keseluruhan model yang dibuat, kita hanya perlu menggunakan satu model saja yang dirasa memiliki performa paling baik.

# Kesimpulan

- <b>Kesimpulan bisnis</b>

Dari keseluruhan proses yang sudah dilakukan, kita dapat menarik kesimpulan bahwa model ARIMA adalah model yang paling baik untuk digunakan dalam memprediksi hasil tambang minyak bumi di Amerika Serikat karena jika dilihat dari rata-rata nilai error yang dihasilkan berdasarkan 4 rentan waktu yang berbeda, model ARIMA lah yang memiliki rata-rata error paling kecil. Selain itu juga, model ARIMA selalu lulus uji asumsi <i>Shapiro-Wilk, Box-Pierce dan Ljung-Box</i> pada 4 rentan waktu yang berbeda. 

Berlandasan dengan hasil evaluasi error dan uji asumsi, kita disini dapat melihat hasil prediksi masa depan dari model ARIMA. Di mana model tersebut menunjukan bahwa hasil tambang minyak bumi di Amerika Serika selama 1 tahun kedepan dari bulan Juli 2018 sampai Juni 2019 akan terus mengalami peningkatan dengan tingkat error MAPE sebesar 6.31%. 

Hasil prediksi tersebut bisa dimanfaatkan oleh pemerintah Amerika Serikat dalam menentukan apakah hasil tambang minyak bumi selama satu tahun kedepan masih mencukupi untuk setiap sektor industrii yang membutuhkan. Jika dirasa dari hasil prediksi hasil tambang minyak bumi tidak mencukupi, makan pemerintah Amerika Serikat bisa mengambil keputusan lebih cepat untuk mengimpor minyak bumi dari negara lain agar tidak mengalami kekurangan. Selain itu, jika dirasa dari hasil prediksi hasil tambang minyak bumi berlimpah, pemerintah dapat mengambil dua keputusan yaitu menurunkan harga jual minyak bumi ataupun melakukan ekspor ke negara lain yang membutuhkan.

- <b>Kesimpulan <i>framework</i> modeltime</b>

Setelah mengimplementasikan <i>framework</i> `modeltime` untuk memprediksi hasil minyak bumi di Amerika Serika. Kita dapat menarik kesimpulan bahwa <i>framework</i> `modeltime` sangat membantu dalam pengerjaan kasus deret waktu karena hanya dengan satu framework saja kita sudah disediakan berbagai macam fitur yang dapat kita manfaatkan untuk setiap tahapannya, 
di mana setiap tahapan yang perlu dilakukan juga sudah disediakan, sehingga proses pengerjaan yang kita lakukan menjadi lebih terstruktur.

Pada artikel ini, kita juga menambahkan satu buah package tambahan yang masih menjadi keluarga `modeltime` yaitu `modeltime.resample`, di mana package tersebut akan membantu pada tahapan <i>cross validation</i> karena dengan bantuan package tersebut kita dapat membagi data latih dan data validasi menjadi ke beberapa kurun waktu yang berbeda. Dengan memiliki beberapa data latih dan data validasi kita dapat melakukan evaluasi terhadap model yang digunakan dengan lebih baik lagi.

Dari beberapa implementasi dari <i>framework</i> `modeltime` yang sudah kita gunakan pada artikel ini, sebenarnya masih ada banyak lagi implementasi yang dapat kita manfaatkan untuk kebutuhan kasus deret waktu lainnya. Eksplorasi lanjutan mengenai apa saja yang dapat dilakukan dengan menggunakan `modeltime` dapat mengunjungi beberapa link referensi di bawah ini.

<b>Referensi:</b>

1. [Getting Started With Modeltime](https://business-science.github.io/modeltime/articles/getting-started-with-modeltime.html)
2. [Getting Started With Modeltime Resample](https://business-science.github.io/modeltime.resample/articles/getting-started.html)
4. [Modeltime Ecosystem Roadmap: New Algorithms & Models](https://github.com/business-science/modeltime/issues/5)
5. [Apply Statistical Tests to Residuals](https://business-science.github.io/modeltime/reference/modeltime_residuals_test.html)



























